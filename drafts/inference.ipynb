{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the generated data from the other notebook. We will also transform $x$ to homogeneous coordinates so that the matrix $A$ will incorporate the bias coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3\n",
      "[[ 1.          1.          1.          1.          1.        ]\n",
      " [ 0.          1.34968621  2.08295411 -0.70582717 -1.70715511]\n",
      " [ 0.         -0.55905218  1.30886104  1.44194285  0.07453323]]\n"
     ]
    }
   ],
   "source": [
    "x = np.load('./simulation/x.npy')\n",
    "z_true = np.load('./simulation/z.npy')\n",
    "\n",
    "print('K =',np.unique(z_true).size)\n",
    "\n",
    "m = x.shape[0]\n",
    "N = x.shape[1]\n",
    "\n",
    "# add dummy variable\n",
    "x = np.concatenate((np.ones(x.shape[1]).reshape(1,-1),x))\n",
    "\n",
    "print(x[:,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior distribution\n",
    "\n",
    "We want to sample the posterior distribution of the parameters and the latent variable $P(A_k,Q_k,\\pi_k,z_t)$. We will sample this with a Gibbs sampler, so we need the conditional version of this posterior distribution given the other parameters (and the observed data as always).\n",
    "\n",
    "#### $P(A_k,Q_k|all)$\n",
    "\n",
    "Once a sequence $z_{1:T}$ is given, the conditioned likelihoods of the grouped data (based on the latent state) are gaussian with dynamical parameters $A_k \\in \\mathbb{R}^{m\\times m+1},Q_k \\in \\mathbb{R}^{m \\times m}$ ($A$ has an added row to account for the bias). That is why, for each $k$, we place a _matrix-normal inverse-Wishart_ prior distribution: \n",
    "\n",
    "$$\n",
    "A_k,Q_k \\sim MNIW(M_k,\\Lambda_k;\\Psi_k,\\nu_k)\n",
    "$$\n",
    "\n",
    "which is the combination of a matrix normal distribution on $A_k$ and an inverse-Wishart distribution on the $Q_k$. Those are the conjugate priors for a multivariate normal likelihood with unknown mean and variance:\n",
    "\n",
    "$$\n",
    "MNIW(A;M,\\Lambda;\\Psi,\\nu) = \\frac{\\exp{(-\\frac{1}{2}}Tr[(A-M)^T Q^{-1}(A-M)\\Lambda^{-1}])}{|Q|^{-m/2}|\\Lambda|^{-n/2}} \\times \\frac{|\\Psi|^{\\nu/2}}{|Q|^{(m+\\nu+1)/2}} \\exp{(-\\frac{1}{2} Tr [\\Psi Q^{-1}])}\n",
    "$$\n",
    "\n",
    "Because of this prior, when we group data by the assigned dyamic $k$, we can do inference on the posterior of these $k$ regressions which is again a _matrix-normal inverse-Wishart_ distribution, with updated parameters:\n",
    "\n",
    "$$\n",
    "A_k,Q_k | all \\sim MNIW(M_k',\\Lambda_k',\\Psi_k',\\nu_k') \\\\ \n",
    "M_k' = \\hat{A}_k X^{(k)}X^{(k)T} \\Lambda_k' + M_k \\Lambda_k^{-1} \\Lambda_k' \\\\\n",
    "\\Lambda_k' = (\\Lambda_k^{-1}+ X^{(k)}X^{(k)T})^{-1}\\\\\n",
    "\\Psi_k' = \\Psi_k + M_k\\Lambda_k^{-1}M_k^T + Y^{(k)}Y^{(k)T}-A_k'(???)\\\\\n",
    "\\nu_k'\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.18134523,  1.5032771 ,  1.58492524],\n",
       "       [-0.31379839,  0.65111482,  0.3735719 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import matrix_normal, invwishart\n",
    "\n",
    "# since P(A,Q) = P(A|Q)P(Q)\n",
    "# we sample Q first and then sample A given Q\n",
    "\n",
    "\n",
    "# ============= INV WISHART\n",
    "\n",
    "# degrees of freedom\n",
    "nu = m\n",
    "# scale matrix, must be symmetric and positive defined\n",
    "psi = np.ones(m)\n",
    "\n",
    "Q = invwishart.rvs(nu,psi)\n",
    "\n",
    "# ============ MATRIX NORMAL\n",
    "# mean of the distribution\n",
    "M = np.zeros((m,m+1))\n",
    "# Q will be the covariance among the rows  (i-th row of A are the coefficient for the regression of the i-th variable)\n",
    "# and lambda will be the covariance among columns (i-th column of A are the coefficients for the i-th variable in the m regression)\n",
    "Lambda = np.eye(m+1)\n",
    "A = matrix_normal.rvs(M,Q,Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $P(\\pi_k|all)$\n",
    "\n",
    "Again, given $z_{t}$, we can count the transitions to state $k$ to state $l$, and write them in a count vector $n_k$, which provides $P(\\pi_k|z_t)$ (the transitions are Markovian, so no other dependence is needed). Since we put a Dirichlet prior on each row of the transition matrix $\\pi_k$ with parameter $\\alpha_k$, the posterior is again a Dirichlet distribution:\n",
    "\n",
    "$$\n",
    "\\pi_k | all \\sim Dir(\\alpha_k + n_k)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs sampler\n",
    "\n",
    "The Gibbs sampler goes as follows:\n",
    "\n",
    "##### Initialize\n",
    "\n",
    "Sample $z_{1:T}$ uniformly, and compute:\n",
    "\n",
    "1. $n_k$ (a vector that counts the transitions from $k$ to any other state)\n",
    "2. $X^{(k)},Y^{(k)}$ (the subsets of data that obey the $k$-th dynamic under the sequence $z_t$)\n",
    "3. $\\{ M_k ',\\Lambda_k ',\\Psi_k ',\\nu_k ' \\}$ the updated parameters of the posterior distribution for $A_k,Q_k$ given observed data and a given sequence $z_{1:T}$\n",
    "\n",
    "then draw $\\Pi, A_k, Q_k$ from the priors.\n",
    "\n",
    "##### Iterations\n",
    "\n",
    "1. $\\forall k$ sample $\\pi_k \\sim Dir(\\alpha_k + n_k)$\n",
    "2. $\\forall k$ sample $A_k,Q_k \\sim MNIW(M_k',\\Lambda_k',\\Psi_k ',\\nu')$\n",
    "3. $\\forall t = 2,\\dots,T$ sample a new Markov trajectory from $P(z_t = k) = r_{tk}/\\sum_k r_{tk}$\n",
    "4. Recompute $n_k,X^{(k)},Y^{(k)},M_k',\\Lambda_k',\\Psi_k',\\nu_k'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b48686ecf5c051869e44bca573c1817bb1844fb32a5df209df0a7813f2e01a7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
